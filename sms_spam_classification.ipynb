## Summary and Conclusions üìù

### Key Findings:

1. **Best Performing Model**: Our analysis shows that different combinations of algorithms and features perform differently
2. **Feature Engineering Impact**: TF-IDF and Count vectorization generally perform well for text classification
3. **Model Comparison**: Each algorithm has its strengths:
   - **Naive Bayes**: Fast and effective for text classification
   - **Logistic Regression**: Good balance of performance and interpretability
   - **SVM**: Can capture complex patterns but slower to train
   - **Random Forest**: Robust but may overfit on text data

### Next Steps:

1. **Hyperparameter Tuning**: Use GridSearchCV to optimize model parameters
2. **Feature Engineering**: Try additional features like message length, special characters count
3. **Ensemble Methods**: Combine multiple models for better performance
4. **Deep Learning**: Experiment with neural networks and pre-trained embeddings
5. **Deployment**: Create a web application or API for real-time spam detection

### Files Generated:
- Model comparison visualizations
- Confusion matrices
- Word clouds
- Performance metrics

---

**üéâ Congratulations! You've successfully built and evaluated multiple SMS spam classification models!**# Interactive prediction cell
print("üéÆ Interactive SMS Spam Detection")
print("=" * 40)
print("Enter your own SMS message to test the classifier!")
print("(Note: In Jupyter, you can modify this cell to test different messages)")

# You can change this message to test different inputs
user_message = "Congratulations! You've won a free iPhone! Click here to claim your prize now!"

print(f"\nüîç Testing message: '{user_message}'")
print("-" * 50)
result, prob = predict_message(user_message)

# Additional analysis
if prob is not None:
    confidence = max(prob) * 100
    if confidence > 80:
        confidence_level = "Very High"
    elif confidence > 60:
        confidence_level = "High"
    elif confidence > 40:
        confidence_level = "Medium"
    else:
        confidence_level = "Low"
    
    print(f"\nüìä Analysis:")
    print(f"   Prediction: {result}")
    print(f"   Confidence Level: {confidence_level} ({confidence:.1f}%)")
    
    if result == 'SPAM' and confidence > 70:
        print("   ‚ö†Ô∏è This message shows strong spam indicators!")
    elif result == 'HAM' and confidence > 70:
        print("   ‚úÖ This message appears to be legitimate.")
    else:
        print("   ‚ùì The model is uncertain about this classification.")# Create prediction function
def predict_message(message, model_key=None):
    """Predict if a message is spam or ham"""
    if model_key is None:
        # Use best model (highest F1-score)
        model_key = max(results.keys(), key=lambda x: results[x]['f1'])
    
    model_name, feature_type = model_key.rsplit('_', 1)
    model = models[model_key]
    
    # Preprocess message
    processed_message = preprocess_text(message)
    
    # Transform message based on feature type
    if feature_type == 'TF-IDF':
        message_features = tfidf.transform([processed_message])
    elif feature_type == 'Count':
        message_features = count_vec.transform([processed_message])
    elif feature_type == 'Word2Vec':
        message_features = get_document_vector(processed_message, w2v_model).reshape(1, -1)
    
    # Make prediction
    prediction = model.predict(message_features)[0]
    probability = model.predict_proba(message_features)[0] if hasattr(model, 'predict_proba') else None
    
    result = 'SPAM' if prediction == 1 else 'HAM'
    
    # Display results
    print(f"üì± Message: '{message}'")
    print(f"üîç Prediction: {result}")
    if probability is not None:
        spam_prob = probability[1] * 100
        ham_prob = probability[0] * 100
        print(f"üìä Confidence: Ham: {ham_prob:.1f}%, Spam: {spam_prob:.1f}%")
    print(f"ü§ñ Model: {model_name} with {feature_type} features")
    
    return result, probability

# Test with sample messages
print("üß™ Testing with sample messages:")
print("=" * 60)

test_messages = [
    "Hi, how are you doing today?",
    "URGENT! You have won $1000! Click here now!",
    "Can you pick up milk on your way home?",
    "FREE! Get your loan approved instantly! Call now!",
    "Meeting scheduled for tomorrow at 2 PM",
    "Congratulations! You are our lucky winner! Claim now!",
    "Thanks for your help with the project yesterday",
    "WINNER! Limited time offer! Act now or lose forever!"
]

for i, msg in enumerate(test_messages):
    print(f"\n{i+1}.")
    predict_message(msg)
    print("-" * 40)## 8. Predictions and Testing üîÆ

Let's test our best model with sample messages and create an interactive prediction function.# Create confusion matrices for top performing models
print("üìä Creating confusion matrices for top models...")

# Get top 4 models by F1-score
top_models = sorted(results.items(), key=lambda x: x[1]['f1'], reverse=True)[:4]

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.ravel()

for i, (model_key, metrics) in enumerate(top_models):
    model_name, feature_type = model_key.rsplit('_', 1)
    
    cm = confusion_matrix(y_test, metrics['y_pred'])
    
    # Create heatmap
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
    
    # Calculate additional metrics for display
    tn, fp, fn, tp = cm.ravel()
    specificity = tn / (tn + fp)
    
    axes[i].set_title(f'{model_name} + {feature_type}\nF1: {metrics["f1"]:.3f}, Spec: {specificity:.3f}', 
                     fontweight='bold')
    axes[i].set_xlabel('Predicted')
    axes[i].set_ylabel('Actual')

plt.tight_layout()
plt.show()

# Print detailed classification reports for top 2 models
print("\nüìã Detailed Classification Reports:")
print("=" * 60)

for i, (model_key, metrics) in enumerate(top_models[:2]):
    model_name, feature_type = model_key.rsplit('_', 1)
    print(f"\n{i+1}. {model_name} with {feature_type} features:")
    print("-" * 50)
    print(classification_report(y_test, metrics['y_pred'], 
                              target_names=['Ham', 'Spam'], digits=4))# Create comprehensive visualization of model performance
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time (s)']

# Create heatmaps for each metric
for i, metric in enumerate(metrics):
    row, col = i // 3, i % 3
    
    # Create pivot table for heatmap
    pivot_data = results_df.pivot(index='Model', columns='Features', values=metric)
    
    # Choose colormap based on metric
    cmap = 'YlOrRd' if metric != 'Training Time (s)' else 'YlOrRd_r'
    
    sns.heatmap(pivot_data, annot=True, cmap=cmap, ax=axes[row, col], 
                fmt='.4f' if metric != 'Training Time (s)' else '.2f',
                cbar_kws={'label': metric})
    axes[row, col].set_title(f'{metric} Comparison', fontweight='bold')
    axes[row, col].set_xlabel('')
    axes[row, col].set_ylabel('')

# Remove the last subplot (we only have 5 metrics)
axes[1, 2].remove()

# Add overall comparison bar plot
ax_bar = fig.add_subplot(2, 3, 6)
models_for_bar = results_df.groupby('Model')['F1-Score'].mean().sort_values(ascending=True)
bars = ax_bar.barh(models_for_bar.index, models_for_bar.values, color='skyblue')
ax_bar.set_xlabel('Average F1-Score')
ax_bar.set_title('Average F1-Score by Model', fontweight='bold')

# Add value labels on bars
for bar, value in zip(bars, models_for_bar.values):
    ax_bar.text(value + 0.005, bar.get_y() + bar.get_height()/2, 
                f'{value:.3f}', ha='left', va='center')

plt.tight_layout()
plt.show()# Create comprehensive results comparison
print("üìä Creating comprehensive model evaluation...")

# Create results DataFrame
results_data = []
for key, metrics in results.items():
    model_name, feature_type = key.rsplit('_', 1)
    results_data.append({
        'Model': model_name,
        'Features': feature_type,
        'Accuracy': metrics['accuracy'],
        'Precision': metrics['precision'],
        'Recall': metrics['recall'],
        'F1-Score': metrics['f1'],
        'Training Time (s)': metrics['training_time']
    })

results_df = pd.DataFrame(results_data)

# Display results
print("üìà Model Performance Comparison:")
print("=" * 80)
display_df = results_df.round(4)
print(display_df.to_string(index=False))

# Find best models
best_accuracy = results_df.loc[results_df['Accuracy'].idxmax()]
best_f1 = results_df.loc[results_df['F1-Score'].idxmax()]
best_precision = results_df.loc[results_df['Precision'].idxmax()]
best_recall = results_df.loc[results_df['Recall'].idxmax()]

print(f"\nüèÜ Best Models:")
print(f"   Accuracy:  {best_accuracy['Model']} + {best_accuracy['Features']} ({best_accuracy['Accuracy']:.4f})")
print(f"   F1-Score:  {best_f1['Model']} + {best_f1['Features']} ({best_f1['F1-Score']:.4f})")
print(f"   Precision: {best_precision['Model']} + {best_precision['Features']} ({best_precision['Precision']:.4f})")
print(f"   Recall:    {best_recall['Model']} + {best_recall['Features']} ({best_recall['Recall']:.4f})")## 7. Model Evaluation üìà

Let's evaluate and compare all trained models to find the best performer.# Train models for each feature set
import time

for feature_name, (X_train, X_test) in feature_sets.items():
    print(f"\nüìä Training models with {feature_name} features...")
    
    for model_name, model in models_config.items():
        print(f"   üîÑ Training {model_name}...")
        
        # Skip Naive Bayes for Word2Vec (requires non-negative features)
        if model_name == 'Naive Bayes' and feature_name == 'Word2Vec':
            print(f"   ‚ö†Ô∏è Skipping {model_name} with {feature_name} (incompatible)")
            continue
        
        try:
            start_time = time.time()
            
            # Train model
            model.fit(X_train, y_train)
            
            # Make predictions
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None
            
            # Calculate metrics
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            
            training_time = time.time() - start_time
            
            # Store results
            key = f"{model_name}_{feature_name}"
            models[key] = model
            results[key] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'training_time': training_time,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba
            }
            
            print(f"   ‚úÖ {model_name}: Accuracy = {accuracy:.4f}, F1 = {f1:.4f} ({training_time:.2f}s)")
            
        except Exception as e:
            print(f"   ‚ùå Error training {model_name} with {feature_name}: {e}")

print("\n‚úÖ Model training completed!")# Define models and feature sets
print("ü§ñ Setting up models and feature sets...")

models_config = {
    'Naive Bayes': MultinomialNB(alpha=1.0),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, C=1.0),
    'SVM': SVC(random_state=42, probability=True, kernel='rbf', C=1.0),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)
}

feature_sets = {
    'TF-IDF': (X_train_tfidf, X_test_tfidf),
    'Count': (X_train_count, X_test_count),
    'Word2Vec': (X_train_w2v, X_test_w2v)
}

# Store results
models = {}
results = {}

print(f"üìä Training {len(models_config)} models with {len(feature_sets)} feature sets...")
print(f"üéØ Total combinations: {len(models_config) * len(feature_sets)}")## 6. Model Training ü§ñ

Now let's train multiple classification models with different feature sets and compare their performance.# 1. TF-IDF Vectorization
print("üìä Creating TF-IDF features...")
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.95)
X_train_tfidf = tfidf.fit_transform(X_train_text)
X_test_tfidf = tfidf.transform(X_test_text)

print(f"   TF-IDF feature matrix shape: {X_train_tfidf.shape}")
print(f"   Feature names (first 10): {tfidf.get_feature_names_out()[:10]}")

# 2. Count Vectorization
print("\nüî¢ Creating Count features...")
count_vec = CountVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.95)
X_train_count = count_vec.fit_transform(X_train_text)
X_test_count = count_vec.transform(X_test_text)

print(f"   Count feature matrix shape: {X_train_count.shape}")

# 3. Word2Vec Embeddings
print("\nüß† Creating Word2Vec embeddings...")

# Prepare sentences for Word2Vec
train_sentences = [simple_preprocess(text) for text in X_train_text]

# Train Word2Vec model
w2v_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, 
                   min_count=1, workers=4, sg=0, epochs=10)

def get_document_vector(text, model, vector_size=100):
    """Convert document to vector by averaging word vectors"""
    words = simple_preprocess(text)
    word_vectors = []
    for word in words:
        if word in model.wv:
            word_vectors.append(model.wv[word])
    
    if word_vectors:
        return np.mean(word_vectors, axis=0)
    else:
        return np.zeros(vector_size)

# Create training and testing vectors
X_train_w2v = np.array([get_document_vector(text, w2v_model) for text in X_train_text])
X_test_w2v = np.array([get_document_vector(text, w2v_model) for text in X_test_text])

print(f"   Word2Vec feature matrix shape: {X_train_w2v.shape}")
print(f"   Word2Vec vocabulary size: {len(w2v_model.wv)}")

print("\n‚úÖ Feature engineering completed!")# Prepare target variable and split data
print("üîß Preparing features and splitting data...")

# Prepare target variable
y = data['label'].map({'ham': 0, 'spam': 1})

# Split the data
X_train_text, X_test_text, y_train, y_test = train_test_split(
    data['processed_message'], y, test_size=0.2, random_state=42, stratify=y
)

print(f"üìä Training set size: {len(X_train_text)}")
print(f"üìä Test set size: {len(X_test_text)}")
print(f"üìä Training label distribution:")
print(y_train.value_counts(normalize=True))## 5. Feature Engineering üß†

Let's create different types of features using TF-IDF, Count Vectorization, and Word2Vec embeddings.# Initialize preprocessing tools
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    """Comprehensive text preprocessing function"""
    # Convert to lowercase
    text = text.lower()
    
    # Remove punctuation and digits
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    
    # Tokenize
    tokens = word_tokenize(text)
    
    # Remove stopwords and stem
    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words and len(token) > 2]
    
    return ' '.join(tokens)

# Apply preprocessing
print("üîß Preprocessing text data...")
data['processed_message'] = data['message'].apply(preprocess_text)

# Show examples of preprocessing
print("\nüìù Preprocessing Examples:")
for i in range(3):
    original = data['message'].iloc[i]
    processed = data['processed_message'].iloc[i]
    label = data['label'].iloc[i]
    
    print(f"\n{i+1}. [{label.upper()}]")
    print(f"   Original:  {original[:80]}...")
    print(f"   Processed: {processed[:80]}...")

print("\n‚úÖ Text preprocessing completed!")## 4. Text Preprocessing üîß

Now let's preprocess the text data to prepare it for machine learning models.# Create word clouds for spam and ham messages
print("‚òÅÔ∏è Creating word clouds...")

# Separate spam and ham messages
spam_text = ' '.join(data[data['label'] == 'spam']['message'])
ham_text = ' '.join(data[data['label'] == 'ham']['message'])

# Create word clouds
fig, axes = plt.subplots(1, 2, figsize=(16, 8))

# Spam word cloud
spam_wordcloud = WordCloud(width=600, height=400, background_color='white', 
                          colormap='Reds', max_words=100).generate(spam_text)
axes[0].imshow(spam_wordcloud, interpolation='bilinear')
axes[0].set_title('Spam Messages Word Cloud', fontsize=16, fontweight='bold')
axes[0].axis('off')

# Ham word cloud
ham_wordcloud = WordCloud(width=600, height=400, background_color='white', 
                         colormap='Blues', max_words=100).generate(ham_text)
axes[1].imshow(ham_wordcloud, interpolation='bilinear')
axes[1].set_title('Ham Messages Word Cloud', fontsize=16, fontweight='bold')
axes[1].axis('off')

plt.tight_layout()
plt.show()# Create comprehensive data visualizations
print("üìä Creating data visualizations...")

# Add additional features for analysis
data['message_length'] = data['message'].str.len()
data['word_count'] = data['message'].str.split().str.len()

# Set up the plotting
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Label distribution (Pie chart)
label_counts = data['label'].value_counts()
axes[0, 0].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%', 
              colors=['lightblue', 'lightcoral'], startangle=90)
axes[0, 0].set_title('Distribution of SMS Labels', fontsize=14, fontweight='bold')

# 2. Message length distribution
spam_lengths = data[data['label'] == 'spam']['message_length']
ham_lengths = data[data['label'] == 'ham']['message_length']

axes[0, 1].hist(ham_lengths, alpha=0.7, label='Ham', bins=50, color='lightblue', density=True)
axes[0, 1].hist(spam_lengths, alpha=0.7, label='Spam', bins=50, color='lightcoral', density=True)
axes[0, 1].set_xlabel('Message Length (characters)')
axes[0, 1].set_ylabel('Density')
axes[0, 1].set_title('Message Length Distribution', fontsize=14, fontweight='bold')
axes[0, 1].legend()

# 3. Word count distribution
spam_words = data[data['label'] == 'spam']['word_count']
ham_words = data[data['label'] == 'ham']['word_count']

axes[1, 0].hist(ham_words, alpha=0.7, label='Ham', bins=30, color='lightblue', density=True)
axes[1, 0].hist(spam_words, alpha=0.7, label='Spam', bins=30, color='lightcoral', density=True)
axes[1, 0].set_xlabel('Word Count')
axes[1, 0].set_ylabel('Density')
axes[1, 0].set_title('Word Count Distribution', fontsize=14, fontweight='bold')
axes[1, 0].legend()

# 4. Box plot for message lengths
data_for_box = [ham_lengths, spam_lengths]
box_plot = axes[1, 1].boxplot(data_for_box, labels=['Ham', 'Spam'], patch_artist=True)
box_plot['boxes'][0].set_facecolor('lightblue')
box_plot['boxes'][1].set_facecolor('lightcoral')
axes[1, 1].set_ylabel('Message Length (characters)')
axes[1, 1].set_title('Message Length Box Plot', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()

# Print statistical summary
print("\nüìä Statistical Summary:")
print("Ham messages:")
print(f"  Average length: {ham_lengths.mean():.1f} characters")
print(f"  Average words: {ham_words.mean():.1f} words")
print("\nSpam messages:")
print(f"  Average length: {spam_lengths.mean():.1f} characters")
print(f"  Average words: {spam_words.mean():.1f} words")## 3. Data Visualization üìà

Let's create comprehensive visualizations to understand our data better.# Load and explore the dataset
print("üìä Loading and exploring the dataset...")

try:
    # Try different encodings
    encodings = ['latin-1', 'utf-8', 'cp1252']
    data = None
    for encoding in encodings:
        try:
            data = pd.read_csv('spam.csv', encoding=encoding)
            break
        except UnicodeDecodeError:
            continue
    
    if data is None:
        raise Exception("Could not read the dataset with any encoding")
    
    # Clean column names and select relevant columns
    if 'v1' in data.columns and 'v2' in data.columns:
        data = data[['v1', 'v2']].copy()
        data.columns = ['label', 'message']
    elif 'Category' in data.columns and 'Message' in data.columns:
        data = data[['Category', 'Message']].copy()
        data.columns = ['label', 'message']
    
    # Remove any rows with missing values
    data = data.dropna()
    
    print(f"‚úÖ Dataset loaded successfully!")
    print(f"üìà Dataset shape: {data.shape}")
    print(f"\nüìã Dataset info:")
    print(data.info())
    print(f"\nüìä Label distribution:")
    print(data['label'].value_counts())
    print(f"\nPercentage distribution:")
    print(data['label'].value_counts(normalize=True) * 100)
    
    # Display sample messages
    print(f"\nüìù Sample messages:")
    for i, (label, message) in enumerate(zip(data['label'][:5], data['message'][:5])):
        print(f"{i+1}. [{label.upper()}] {message[:100]}...")
        
except Exception as e:
    print(f"‚ùå Error loading dataset: {e}")def download_dataset():
    """Download the SMS spam dataset"""
    print("üì• Downloading SMS Spam Dataset...")
    
    # URL for the SMS Spam Collection dataset
    url = "https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv"
    
    try:
        # Download the dataset
        response = requests.get(url)
        response.raise_for_status()
        
        # Save to file
        with open('spam.csv', 'wb') as f:
            f.write(response.content)
        
        print("‚úÖ Dataset downloaded successfully!")
        return True
        
    except Exception as e:
        print(f"‚ùå Error downloading dataset: {e}")
        print("üìù Creating sample dataset for demonstration...")
        create_sample_dataset()
        return False

def create_sample_dataset():
    """Create a sample dataset if download fails"""
    sample_data = {
        'v1': ['ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam'] * 100,
        'v2': [
            'How are you doing today?',
            'URGENT! You have won $1000! Click here now!',
            'Can you pick up milk on your way home?',
            'FREE! Get your loan approved instantly! Call now!',
            'Meeting at 3pm today in conference room',
            'Congratulations! You are selected for cash prize!',
            'Thanks for the help yesterday',
            'WINNER! Claim your prize now! Limited time offer!'
        ] * 100
    }
    
    df = pd.DataFrame(sample_data)
    df.to_csv('spam.csv', index=False)
    print("‚úÖ Sample dataset created!")

# Download the dataset
download_dataset()## 2. Data Loading and Exploration üìä

Let's download and explore the SMS spam dataset.# Install required packages (run this cell first if packages are not installed)
# !pip install pandas numpy scikit-learn matplotlib seaborn nltk wordcloud gensim requests

# Import all necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (classification_report, confusion_matrix, 
                           accuracy_score, precision_score, recall_score, 
                           f1_score, roc_auc_score, roc_curve)
from sklearn.pipeline import Pipeline
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from wordcloud import WordCloud
import re
import string
import warnings
import os
import requests
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess

# Configure display settings
warnings.filterwarnings('ignore')
plt.style.use('default')
sns.set_palette("husl")

# Download required NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
    
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

print("‚úÖ All libraries imported successfully!")
print("üì¶ NLTK data downloaded!")## 1. Setup and Installation üîß

First, let's install all required packages and import necessary libraries.# SMS Spam Classification System üì±ü§ñ

This comprehensive notebook implements an AI model for classifying SMS messages as spam or legitimate using:

- **TF-IDF Vectorization** üìä
- **Word Embeddings (Word2Vec)** üß†
- **Multiple Classifiers**: Naive Bayes, Logistic Regression, SVM, Random Forest üéØ
- **Comprehensive Evaluation** üìà

## Table of Contents
1. [Setup and Installation](#setup)
2. [Data Loading and Exploration](#data)
3. [Data Visualization](#visualization)
4. [Text Preprocessing](#preprocessing)
5. [Feature Engineering](#features)
6. [Model Training](#training)
7. [Model Evaluation](#evaluation)
8. [Predictions and Testing](#predictions)

---